<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>hossam.classification API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>hossam.classification</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import inspect

# import logging
import numpy as np
import concurrent.futures as futures

from pandas import DataFrame, Series, concat
from sklearn.metrics import (
    log_loss,
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
)
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import LinearSVC, SVC
from sklearn.naive_bayes import GaussianNB
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import SGDClassifier

from scipy.stats import norm

from .util import my_pretty_table
from .plot import my_learing_curve, my_confusion_matrix, my_roc_curve, my_tree
from .core import __ml


def __my_classification(
    classname: any,
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = False,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    pruning: bool = False,
    **params,
) -&gt; any:
    &#34;&#34;&#34;분류분석을 수행하고 결과를 출력한다.

    Args:
        classname (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법. Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        pruning (bool, optional): 의사결정나무에서 가지치기의 alpha값을 하이퍼 파라미터 튜닝에 포함 할지 여부. Default to False.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        any: 분류분석 모델
    &#34;&#34;&#34;
    # ------------------------------------------------------
    # 분석모델 생성
    estimator = __ml(
        classname=classname,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        cv=cv,
        is_print=is_print,
        **params,
    )

    # ------------------------------------------------------
    # 성능평가
    if x_test is not None and y_test is not None:
        my_classification_result(
            estimator,
            x_train=x_train,
            y_train=y_train,
            x_test=x_test,
            y_test=y_test,
            conf_matrix=conf_matrix,
            hist=hist,
            roc=roc,
            pr=pr,
            multiclass=multiclass,
            learning_curve=learning_curve,
            cv=cv,
            figsize=figsize,
            dpi=dpi,
            is_print=is_print,
        )
    else:
        my_classification_result(
            estimator,
            x_train=x_train,
            y_train=y_train,
            conf_matrix=conf_matrix,
            hist=hist,
            roc=roc,
            pr=pr,
            multiclass=multiclass,
            learning_curve=learning_curve,
            cv=cv,
            figsize=figsize,
            dpi=dpi,
            is_print=is_print,
        )

    # ------------------------------------------------------
    # 보고서 출력
    if report and is_print:
        my_classification_report(estimator, x_train, y_train, x_test, y_test, sort)

    return estimator


def my_classification_result(
    estimator: any,
    x_train: DataFrame = None,
    y_train: Series = None,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve: bool = True,
    cv: int = 10,
    figsize: tuple = (12, 5),
    dpi: int = 100,
    is_print: bool = True,
) -&gt; None:
    &#34;&#34;&#34;회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법(ovo, ovr, None). Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to False.
        cv (int, optional): 교차검증 횟수. Defaults to 10.
        figsize (tuple, optional): 그래프의 크기. Defaults to (12, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        is_print (bool, optional): 출력 여부. Defaults to True.
    &#34;&#34;&#34;

    # ------------------------------------------------------
    # 성능평가

    scores = []
    score_names = []

    # 이진분류인지 다항분류인지 구분
    labels = list(estimator.classes_)
    is_binary = len(labels) == 2

    if x_train is not None and y_train is not None:
        # 추정치
        y_train_pred = estimator.predict(x_train)

        if hasattr(estimator, &#34;predict_proba&#34;):
            y_train_pred_proba = estimator.predict_proba(x_train)
            y_train_pred_proba_1 = y_train_pred_proba[:, 1]

        # 의사결정계수 --&gt; 다항로지스틱에서는 사용 X
        y_train_pseudo_r2 = 0

        if is_binary and estimator.__class__.__name__ == &#34;LogisticRegression&#34;:
            y_train_log_loss_test = -log_loss(
                y_train, y_train_pred_proba, normalize=False
            )
            y_train_null = np.ones_like(y_train) * y_train.mean()
            y_train_log_loss_null = -log_loss(y_train, y_train_null, normalize=False)
            y_train_pseudo_r2 = 1 - (y_train_log_loss_test / y_train_log_loss_null)

        # 혼동행렬
        y_train_conf_mat = confusion_matrix(y_train, y_train_pred)

        # 성능평가
        # 의사결정계수, 위양성율, 특이성, AUC는 다항로지스틱에서는 사용 불가
        # 나머지 항목들은 코드 변경 예정
        if is_binary:
            ((TN, FP), (FN, TP)) = y_train_conf_mat

            result = {
                &#34;의사결정계수(Pseudo R2)&#34;: y_train_pseudo_r2,
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_train, y_train_pred),
                &#34;정밀도(Precision)&#34;: precision_score(y_train, y_train_pred),
                &#34;재현율(Recall)&#34;: recall_score(y_train, y_train_pred),
                &#34;위양성율(Fallout)&#34;: FP / (TN + FP),
                &#34;특이성(TNR)&#34;: 1 - (FP / (TN + FP)),
                &#34;F1 Score&#34;: f1_score(y_train, y_train_pred),
            }

            if hasattr(estimator, &#34;predict_proba&#34;):
                result[&#34;AUC&#34;] = roc_auc_score(y_train, y_train_pred_proba_1)
        else:
            result = {
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_train, y_train_pred),
                &#34;정밀도(Precision)&#34;: precision_score(
                    y_train, y_train_pred, average=&#34;macro&#34;
                ),
                &#34;재현율(Recall)&#34;: recall_score(y_train, y_train_pred, average=&#34;micro&#34;),
                &#34;F1 Score&#34;: f1_score(y_train, y_train_pred, average=&#34;macro&#34;),
            }

            if hasattr(estimator, &#34;predict_proba&#34;):
                if multiclass == &#34;ovo&#34; or multiclass == None:
                    result[&#34;AUC(ovo)&#34;] = roc_auc_score(
                        y_train, y_train_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovo&#34;
                    )

                if multiclass == &#34;ovr&#34; or multiclass == None:
                    result[&#34;AUC(ovr)&#34;] = roc_auc_score(
                        y_train, y_train_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovr&#34;
                    )

        scores.append(result)
        score_names.append(&#34;훈련데이터&#34;)

    if x_test is not None and y_test is not None:
        # 추정치
        y_test_pred = estimator.predict(x_test)

        if hasattr(estimator, &#34;predict_proba&#34;):
            y_test_pred_proba = estimator.predict_proba(x_test)
            y_test_pred_proba_1 = y_test_pred_proba[:, 1]

        # 의사결정계수
        y_test_pseudo_r2 = 0

        if is_binary and estimator.__class__.__name__ == &#34;LogisticRegression&#34;:
            y_test_log_loss_test = -log_loss(y_test, y_test_pred_proba, normalize=False)
            y_test_null = np.ones_like(y_test) * y_test.mean()
            y_test_log_loss_null = -log_loss(y_test, y_test_null, normalize=False)
            y_test_pseudo_r2 = 1 - (y_test_log_loss_test / y_test_log_loss_null)

        # 혼동행렬
        y_test_conf_mat = confusion_matrix(y_test, y_test_pred)

        if is_binary:
            # TN,FP,FN,TP
            ((TN, FP), (FN, TP)) = y_test_conf_mat

            # 성능평가
            result = {
                &#34;의사결정계수(Pseudo R2)&#34;: y_test_pseudo_r2,
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_test, y_test_pred),
                &#34;정밀도(Precision)&#34;: precision_score(y_test, y_test_pred),
                &#34;재현율(Recall)&#34;: recall_score(y_test, y_test_pred),
                &#34;위양성율(Fallout)&#34;: FP / (TN + FP),
                &#34;특이성(TNR)&#34;: 1 - (FP / (TN + FP)),
                &#34;F1 Score&#34;: f1_score(y_test, y_test_pred),
            }

            if hasattr(estimator, &#34;predict_proba&#34;):
                result[&#34;AUC&#34;] = roc_auc_score(y_test, y_test_pred_proba_1)
        else:
            result = {
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_test, y_test_pred),
                &#34;정밀도(Precision)&#34;: precision_score(
                    y_test, y_test_pred, average=&#34;macro&#34;
                ),
                &#34;재현율(Recall)&#34;: recall_score(y_test, y_test_pred, average=&#34;macro&#34;),
                &#34;F1 Score&#34;: f1_score(y_test, y_test_pred, average=&#34;macro&#34;),
            }

            if hasattr(estimator, &#34;predict_proba&#34;):
                if multiclass == &#34;ovo&#34; or multiclass == None:
                    result[&#34;AUC(ovo)&#34;] = roc_auc_score(
                        y_test, y_test_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovo&#34;
                    )

                if multiclass == &#34;ovr&#34; or multiclass == None:
                    result[&#34;AUC(ovr)&#34;] = roc_auc_score(
                        y_test, y_test_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovr&#34;
                    )

        scores.append(result)
        score_names.append(&#34;검증데이터&#34;)

    # 각 항목의 설명 추가
    if is_binary:
        result = {
            &#34;의사결정계수(Pseudo R2)&#34;: &#34;로지스틱회귀의 성능 측정 지표로, 1에 가까울수록 좋은 모델&#34;,
            &#34;정확도(Accuracy)&#34;: &#34;예측 결과(TN,FP,TP,TN)가 실제 결과(TP,TN)와 일치하는 정도&#34;,
            &#34;정밀도(Precision)&#34;: &#34;양성으로 예측한 결과(TP,FP) 중 실제 양성(TP)인 비율&#34;,
            &#34;재현율(Recall)&#34;: &#34;실제 양성(TP,FN) 중 양성(TP)으로 예측한 비율&#34;,
            &#34;위양성율(Fallout)&#34;: &#34;실제 음성(FP,TN) 중 양성(FP)으로 잘못 예측한 비율&#34;,
            &#34;특이성(TNR)&#34;: &#34;실제 음성(FP,TN) 중 음성(TN)으로 정확히 예측한 비율&#34;,
            &#34;F1 Score&#34;: &#34;정밀도와 재현율의 조화평균&#34;,
        }

        if hasattr(estimator, &#34;predict_proba&#34;):
            result[&#34;AUC&#34;] = &#34;ROC Curve의 면적으로, 1에 가까울수록 좋은 모델&#34;
    else:
        result = {
            &#34;정확도(Accuracy)&#34;: &#34;예측 결과(TN,FP,TP,TN)가 실제 결과(TP,TN)와 일치하는 정도&#34;,
            &#34;정밀도(Precision)&#34;: &#34;양성으로 예측한 결과(TP,FP) 중 실제 양성(TP)인 비율&#34;,
            &#34;재현율(Recall)&#34;: &#34;실제 양성(TP,FN) 중 양성(TP)으로 예측한 비율&#34;,
            &#34;F1 Score&#34;: &#34;정밀도와 재현율의 조화평균&#34;,
        }

        if hasattr(estimator, &#34;predict_proba&#34;):
            if multiclass == &#34;ovo&#34; or multiclass == None:
                result[&#34;AUC(ovo)&#34;] = &#34;One vs One에 대한 AUC로, 1에 가까울수록 좋은 모델&#34;

            if multiclass == &#34;ovr&#34; or multiclass == None:
                result[&#34;AUC(ovr)&#34;] = (
                    &#34;One vs Rest에 대한 AUC로, 1에 가까울수록 좋은 모델&#34;
                )

    scores.append(result)
    score_names.append(&#34;설명&#34;)

    if is_print:
        print(&#34;[분류분석 성능평가]&#34;)
        result_df = DataFrame(scores, index=score_names)

        if estimator.__class__.__name__ != &#34;LogisticRegression&#34;:
            if &#34;의사결정계수(Pseudo R2)&#34; in result_df.columns:
                result_df.drop(columns=[&#34;의사결정계수(Pseudo R2)&#34;], inplace=True)

        my_pretty_table(result_df.T)

    # 결과값을 모델 객체에 포함시킴
    estimator.scores = scores[-2]

    # ------------------------------------------------------
    # 혼동행렬
    if conf_matrix and is_print:
        print(&#34;\n[혼동행렬]&#34;)

        if x_test is not None and y_test is not None:
            my_confusion_matrix(y_test, y_test_pred, figsize=figsize, dpi=dpi)
        else:
            my_confusion_matrix(y_train, y_train_pred, figsize=figsize, dpi=dpi)

    # ------------------------------------------------------
    # curve
    if is_print:
        if hasattr(estimator, &#34;predict_proba&#34;):

            if x_test is None or y_test is None:
                print(&#34;\n[Roc Curve]&#34;)
                my_roc_curve(
                    estimator,
                    x_train,
                    y_train,
                    hist=hist,
                    roc=roc,
                    pr=pr,
                    multiclass=multiclass,
                    dpi=dpi,
                )
            else:
                print(&#34;\n[Roc Curve]&#34;)
                my_roc_curve(
                    estimator,
                    x_test,
                    y_test,
                    hist=hist,
                    roc=roc,
                    pr=pr,
                    multiclass=multiclass,
                    dpi=dpi,
                )

        # 학습곡선
        if learning_curve:
            print(&#34;\n[학습곡선]&#34;)
            yname = y_train.name

            if x_test is not None and y_test is not None:
                y_df = concat([y_train, y_test])
                x_df = concat([x_train, x_test])
            else:
                y_df = y_train.copy()
                x_df = x_train.copy()

            x_df[yname] = y_df
            x_df.sort_index(inplace=True)

            if cv &gt; 0:
                my_learing_curve(
                    estimator, data=x_df, yname=yname, cv=cv, figsize=figsize, dpi=dpi
                )
            else:
                my_learing_curve(
                    estimator, data=x_df, yname=yname, figsize=figsize, dpi=dpi
                )

        if estimator.__class__.__name__ == &#34;DecisionTreeClassifier&#34;:
            my_tree(estimator)


def my_classification_report(
    estimator: any,
    x_train: DataFrame = None,
    y_train: Series = None,
    x_test: DataFrame = None,
    y_test: Series = None,
    sort: str = None,
) -&gt; None:
    &#34;&#34;&#34;분류분석 결과를 이항분류와 다항분류로 구분하여 출력한다. 훈련데이터와 검증데이터가 함께 전달 될 경우 검증 데이터를 우선한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame, optional): 훈련 데이터의 독립변수. Defaults to None.
        y_train (Series, optional): 훈련 데이터의 종속변수. Defaults to None.
        x_test (DataFrame, optional): 검증 데이터의 독립변수. Defaults to None.
        y_test (Series, optional): 검증 데이터의 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    is_binary = len(estimator.classes_) == 2

    if is_binary:
        if x_test is not None and y_test is not None:
            my_classification_binary_report(estimator, x=x_test, y=y_test, sort=sort)
        else:
            my_classification_binary_report(estimator, x=x_train, y=y_train, sort=sort)
    else:
        if x_test is not None and y_test is not None:
            my_classification_multiclass_report(
                estimator, x=x_test, y=y_test, sort=sort
            )
        else:
            my_classification_multiclass_report(
                estimator, x=x_train, y=y_train, sort=sort
            )


def my_classification_binary_report(
    estimator: any, x: DataFrame = None, y: Series = None, sort: str = None
) -&gt; None:
    &#34;&#34;&#34;이항로지스틱 회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x (DataFrame, optional): 독립변수. Defaults to None.
        y (Series, optional): 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    if estimator.__class__.__name__ == &#34;LogisticRegression&#34;:
        # 추정 확률
        y_pred_proba = estimator.predict_proba(x)

        # 추정확률의 길이(=샘플수)
        n = len(y_pred_proba)

        # 계수의 수 + 1(절편)
        m = len(estimator.coef_[0]) + 1

        # 절편과 계수를 하나의 배열로 결합
        coefs = np.concatenate([estimator.intercept_, estimator.coef_[0]])

        # 상수항 추가
        x_full = np.matrix(np.insert(np.array(x), 0, 1, axis=1))

        # 변수의 길이를 활용하여 모든 값이 0인 행렬 생성
        ans = np.zeros((m, m))

        # 표준오차
        for i in range(n):
            ans = (
                ans
                + np.dot(np.transpose(x_full[i, :]), x_full[i, :])
                * y_pred_proba[i, 1]
                * y_pred_proba[i, 0]
            )

        vcov = np.linalg.inv(np.matrix(ans))
        se = np.sqrt(np.diag(vcov))

        # t값
        t = coefs / se

        # p-value
        p_values = (1 - norm.cdf(abs(t))) * 2

        # VIF
        if len(x.columns) &gt; 1:
            vif = [
                variance_inflation_factor(x, list(x.columns).index(v))
                for i, v in enumerate(x.columns)
            ]
        else:
            vif = 0

        # 결과표 생성
        xnames = estimator.feature_names_in_

        result_df = DataFrame(
            {
                &#34;종속변수&#34;: [y.name] * len(xnames),
                &#34;독립변수&#34;: xnames,
                &#34;B(비표준화 계수)&#34;: np.round(estimator.coef_[0], 4),
                &#34;표준오차&#34;: np.round(se[1:], 3),
                &#34;t&#34;: np.round(t[1:], 4),
                &#34;유의확률&#34;: np.round(p_values[1:], 3),
                &#34;VIF&#34;: vif,
                &#34;OddsRate&#34;: np.round(np.exp(estimator.coef_[0]), 4),
            }
        )

        if sort:
            if sort.upper() == &#34;V&#34;:
                result_df.sort_values(&#34;VIF&#34;, inplace=True)
            elif sort.upper() == &#34;P&#34;:
                result_df.sort_values(&#34;유의확률&#34;, inplace=True)

        my_pretty_table(result_df)
    else:
        # VIF
        if len(x.columns) &gt; 1:
            vif = [
                variance_inflation_factor(x, list(x.columns).index(v))
                for i, v in enumerate(x.columns)
            ]
        else:
            vif = 0

        # 결과표 생성
        xnames = estimator.feature_names_in_

        result_df = DataFrame(
            {
                &#34;종속변수&#34;: [y.name] * len(xnames),
                &#34;독립변수&#34;: xnames,
                &#34;VIF&#34;: vif,
            }
        )

        if sort:
            if sort.upper() == &#34;V&#34;:
                result_df.sort_values(&#34;VIF&#34;, inplace=True)

        my_pretty_table(result_df)


def my_classification_multiclass_report(
    estimator: any,
    x: DataFrame = None,
    y: Series = None,
    sort: str = None,
) -&gt; None:
    &#34;&#34;&#34;다중로지스틱 회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x (DataFrame, optional): 독립변수. Defaults to None.
        y (Series, optional): 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    class_list = list(estimator.classes_)
    class_size = len(class_list)

    if estimator.__class__.__name__ == &#34;LogisticRegression&#34;:
        # 추정 확률
        y_pred_proba = estimator.predict_proba(x)

        # 추정확률의 길이(=샘플수)
        n = len(y_pred_proba)

        for i in range(0, class_size):
            # 계수의 수 + 1(절편)
            m = len(estimator.coef_[i]) + 1

            # 절편과 계수를 하나의 배열로 결합
            coefs = np.concatenate([[estimator.intercept_[i]], estimator.coef_[i]])

            # 상수항 추가
            x_full = np.matrix(np.insert(np.array(x), 0, 1, axis=1))

            # 변수의 길이를 활용하여 모든 값이 0인 행렬 생성
            ans = np.zeros((m, m))

            # 표준오차
            for j in range(n):
                ans = (
                    ans
                    + np.dot(np.transpose(x_full[j, :]), x_full[j, :])
                    * y_pred_proba[j, i]
                )

            vcov = np.linalg.inv(np.matrix(ans))
            se = np.sqrt(np.diag(vcov))

            # t값
            t = coefs / se

            # p-value
            p_values = (1 - norm.cdf(abs(t))) * 2

            # VIF
            if len(x.columns) &gt; 1:
                vif = [
                    variance_inflation_factor(x, list(x.columns).index(v))
                    for i, v in enumerate(x.columns)
                ]
            else:
                vif = 0

            # 결과표 생성
            xnames = estimator.feature_names_in_

            result_df = DataFrame(
                {
                    &#34;종속변수&#34;: [y.name] * len(xnames),
                    &#34;CLASS&#34;: [class_list[i]] * len(xnames),
                    &#34;독립변수&#34;: xnames,
                    &#34;B(계수)&#34;: np.round(estimator.coef_[i], 4),
                    &#34;표준오차&#34;: np.round(se[1:], 3),
                    &#34;t&#34;: np.round(t[1:], 4),
                    &#34;유의확률&#34;: np.round(p_values[1:], 3),
                    &#34;VIF&#34;: vif,
                    &#34;OddsRate&#34;: np.round(np.exp(estimator.coef_[i]), 4),
                }
            )

            if sort:
                if sort.upper() == &#34;V&#34;:
                    result_df.sort_values(&#34;VIF&#34;, inplace=True)
                elif sort.upper() == &#34;P&#34;:
                    result_df.sort_values(&#34;유의확률&#34;, inplace=True)

            my_pretty_table(result_df)
    else:
        for i in range(0, class_size):
            # VIF
            if len(x.columns) &gt; 1:
                vif = [
                    variance_inflation_factor(x, list(x.columns).index(v))
                    for i, v in enumerate(x.columns)
                ]
            else:
                vif = 0

            # 결과표 생성
            xnames = estimator.feature_names_in_

            result_df = DataFrame(
                {
                    &#34;종속변수&#34;: [y.name] * len(xnames),
                    &#34;CLASS&#34;: [class_list[i]] * len(xnames),
                    &#34;독립변수&#34;: xnames,
                    &#34;VIF&#34;: vif,
                }
            )

            if sort:
                if sort.upper() == &#34;V&#34;:
                    result_df.sort_values(&#34;VIF&#34;, inplace=True)

            my_pretty_table(result_df)


def my_logistic_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; LogisticRegression:
    &#34;&#34;&#34;로지스틱 회귀분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법. Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        LogisticRegression: 회귀분석 모델
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;penalty&#34;: [&#34;l1&#34;, &#34;l2&#34;, &#34;elasticnet&#34;],
                &#34;C&#34;: [0.001, 0.01, 0.1, 1, 10, 100],
                &#34;max_iter&#34;: [1000],
            }

    return __my_classification(
        classname=LogisticRegression,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        **params,
    )


def my_knn_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; KNeighborsClassifier:
    &#34;&#34;&#34;KNN 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법. Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        KNeighborsClassifier
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;n_neighbors&#34;: [3, 5, 7],
                &#34;weights&#34;: [&#34;uniform&#34;, &#34;distance&#34;],
                &#34;metric&#34;: [&#34;euclidean&#34;, &#34;manhattan&#34;],
            }

    return __my_classification(
        classname=KNeighborsClassifier,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        **params,
    )


def my_nb_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; GaussianNB:
    &#34;&#34;&#34;나이브베이즈 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        SVC
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                # &#34;priors&#34; : None,
                &#34;var_smoothing&#34;: [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]
            }

    return __my_classification(
        classname=GaussianNB,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        **params,
    )


def my_dtree_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    pruning: bool = False,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; DecisionTreeClassifier:
    &#34;&#34;&#34;의사결정나무 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        pruning (bool, optional): 의사결정나무에서 가지치기의 alpha값을 하이퍼 파라미터 튜닝에 포함 할지 여부. Default to False.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        DecisionTreeClassifier
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;criterion&#34;: [&#34;gini&#34;, &#34;entropy&#34;],
                # &#34;min_samples_split&#34;: [2, 3, 4],
                # &#34;min_samples_leaf&#34;: [1, 2, 3],
            }

    return __my_classification(
        classname=DecisionTreeClassifier,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        pruning=pruning,
        **params,
    )


def my_linear_svc_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    is_print: bool = True,
    **params,
) -&gt; LinearSVC:
    &#34;&#34;&#34;선형 SVM 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        LinearSVC
    &#34;&#34;&#34;

    if &#34;hist&#34; in params:
        del params[&#34;hist&#34;]
    if &#34;roc&#34; in params:
        del params[&#34;roc&#34;]
    if &#34;pr&#34; in params:
        del params[&#34;pr&#34;]
    if &#34;report&#34; in params:
        del params[&#34;report&#34;]

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;penalty&#34;: [&#34;l1&#34;, &#34;l2&#34;],
                &#34;loss&#34;: [&#34;squared_hinge&#34;, &#34;hinge&#34;],
                &#34;C&#34;: [0.01, 0.1, 1, 10],
                &#34;max_iter&#34;: [1000],
                &#34;dual&#34;: [True, False],
            }

    return __my_classification(
        classname=LinearSVC,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        is_print=is_print,
        **params,
    )


def my_svc_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    # hist: bool = True,
    # roc: bool = True,
    # pr: bool = True,
    # multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    is_print: bool = True,
    **params,
) -&gt; SVC:
    &#34;&#34;&#34;SVC 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        SVC
    &#34;&#34;&#34;

    if &#34;hist&#34; in params:
        del params[&#34;hist&#34;]
    if &#34;roc&#34; in params:
        del params[&#34;roc&#34;]
    if &#34;pr&#34; in params:
        del params[&#34;pr&#34;]
    if &#34;report&#34; in params:
        del params[&#34;report&#34;]

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;C&#34;: [0.1, 1, 10],
                # &#34;kernel&#34;: [&#34;rbf&#34;, &#34;linear&#34;, &#34;poly&#34;, &#34;sigmoid&#34;],
                &#34;kernel&#34;: [&#34;rbf&#34;, &#34;poly&#34;, &#34;sigmoid&#34;],
                &#34;degree&#34;: [2, 3, 4, 5],
                # &#34;gamma&#34;: [&#34;scale&#34;, &#34;auto&#34;],
                # &#34;coef0&#34;: [0.01, 0.1, 1, 10],
                # &#34;shrinking&#34;: [True, False],
                # &#34;probability&#34;: [True],  # AUC 값 확인을 위해서는 True로 설정
            }

    return __my_classification(
        classname=SVC,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        # hist=hist,
        # roc=roc,
        # pr=pr,
        # multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        is_print=is_print,
        **params,
    )


def my_sgd_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; SGDClassifier:
    &#34;&#34;&#34;SGD 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        SGDClassifier
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                # 손실함수
                # &#39;log_loss&#39;, &#39;squared_hinge&#39;, &#39;perceptron&#39;, &#39;squared_error&#39;, &#39;hinge&#39;, &#39;huber&#39;, &#39;squared_epsilon_insensitive&#39;, &#39;epsilon_insensitive&#39;, &#39;modified_huber&#39;
                &#34;loss&#34;: [&#34;hinge&#34;, &#34;log_loss&#34;, &#34;modified_huber&#34;],
                # 정규화 종류
                &#34;penalty&#34;: [&#34;l2&#34;, &#34;l1&#34;, &#34;elasticnet&#34;],
                # 정규화 강도(값이 낮을 수록 약한 정규화)
                &#34;alpha&#34;: [0.0001, 0.001, 0.01, 0.1],
                # 최대 반복 수행 횟수
                &#34;max_iter&#34;: [1000, 2000, 3000, 4000, 5000],
                # 학습률 스케줄링 전략
                &#34;learning_rate&#34;: [&#34;optimal&#34;, &#34;constant&#34;, &#34;invscaling&#34;, &#34;adaptive&#34;],
                # 초기 학습률
                &#34;eta0&#34;: [0.01, 0.1, 0.5],
            }

    return __my_classification(
        classname=SGDClassifier,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        **params,
    )


def my_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = False,
    roc: bool = False,
    pr: bool = False,
    multiclass: str = None,
    learning_curve=False,
    report: bool = False,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    algorithm: list = None,
    pruning: bool = False,
    **params,
) -&gt; DataFrame:
    &#34;&#34;&#34;분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 훈련 데이터의 독립변수
        y_train (Series): 훈련 데이터의 종속변수
        x_test (DataFrame, optional): 검증 데이터의 독립변수. Defaults to None.
        y_test (Series, optional): 검증 데이터의 종속변수. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to False.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to False.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to False.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법. Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to False.
        report (bool, optional): 독립변수 보고를 출력할지 여부. Defaults to False.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        algorithm (list, optional): 사용하고자 하는 분류분석 알고리즘 리스트. None으로 설정할 경우 모든 알고리즘 수행 [&#39;logistic&#39;, &#39;knn&#39;, &#39;dtree&#39;, &#39;svc&#39;, &#39;sgd&#39;]. Defaults to None.
        pruning (bool, optional): 의사결정나무에서 가지치기의 alpha값을 하이퍼 파라미터 튜닝에 포함 할지 여부. Default to False.

    Returns:
        DataFrame: 분류분석 결과
    &#34;&#34;&#34;

    results = []  # 결과값을 저장할 리스트
    processes = []  # 병렬처리를 위한 프로세스 리스트
    estimators = {}  # 분류분석 모델을 저장할 딕셔너리
    estimator_names = []  # 분류분석 모델의 이름을 저장할 문자열 리스트

    callstack = []

    if not algorithm or &#34;logistic&#34; in algorithm:
        callstack.append(my_logistic_classification)

    if not algorithm or &#34;knn&#34; in algorithm:
        callstack.append(my_knn_classification)

    if not algorithm or &#34;svc&#34; in algorithm:
        callstack.append(my_svc_classification)

    if not algorithm or &#34;nb&#34; in algorithm:
        callstack.append(my_nb_classification)

    if not algorithm or &#34;dtree&#34; in algorithm:
        callstack.append(my_dtree_classification)

    if not algorithm or &#34;sgd&#34; in algorithm:
        callstack.append(my_sgd_classification)

    # 병렬처리를 위한 프로세스 생성 -&gt; 분류 모델을 생성하는 함수를 각각 호출한다.
    with futures.ThreadPoolExecutor() as executor:
        for c in callstack:
            processes.append(
                executor.submit(
                    c,
                    x_train=x_train,
                    y_train=y_train,
                    x_test=x_test,
                    y_test=y_test,
                    conf_matrix=conf_matrix,
                    cv=cv,
                    hist=hist,
                    roc=roc,
                    pr=pr,
                    multiclass=multiclass,
                    learning_curve=learning_curve,
                    report=report,
                    figsize=figsize,
                    dpi=dpi,
                    sort=sort,
                    is_print=False,
                    **params,
                )
            )

        # 병렬처리 결과를 기다린다.
        for p in futures.as_completed(processes):
            # 각 분류 함수의 결과값(분류모형 객체)을 저장한다.
            estimator = p.result()

            if estimator is not None:
                # 분류모형 객체가 포함하고 있는 성능 평가지표(딕셔너리)를 복사한다.
                scores = estimator.scores
                # 분류모형의 이름과 객체를 저장한다.
                n = estimator.__class__.__name__
                estimator_names.append(n)
                estimators[n] = estimator
                # 성능평가 지표 딕셔너리를 리스트에 저장
                results.append(scores)

        # 결과값을 데이터프레임으로 변환
        result_df = DataFrame(results, index=estimator_names)
        my_pretty_table(result_df)

    return estimators</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="hossam.classification.my_classification"><code class="name flex">
<span>def <span class="ident">my_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, cv: int = 5, hist: bool = False, roc: bool = False, pr: bool = False, multiclass: str = None, learning_curve=False, report: bool = False, figsize=(10, 5), dpi: int = 100, sort: str = None, algorithm: list = None, pruning: bool = False, **params) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>분류분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>훈련 데이터의 독립변수</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>훈련 데이터의 종속변수</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>검증 데이터의 독립변수. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>검증 데이터의 종속변수. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>hist</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>히스토그램을 출력할지 여부. Defaults to False.</dd>
<dt><strong><code>roc</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>ROC Curve를 출력할지 여부. Defaults to False.</dd>
<dt><strong><code>pr</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>PR Curve를 출력할지 여부. Defaults to False.</dd>
<dt><strong><code>multiclass</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>다항분류일 경우, 다항분류 방법. Defaults to None.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to False.</dd>
<dt><strong><code>report</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>독립변수 보고를 출력할지 여부. Defaults to False.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
<dt><strong><code>algorithm</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>사용하고자 하는 분류분석 알고리즘 리스트. None으로 설정할 경우 모든 알고리즘 수행 ['logistic', 'knn', 'dtree', 'svc', 'sgd']. Defaults to None.</dd>
<dt><strong><code>pruning</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>의사결정나무에서 가지치기의 alpha값을 하이퍼 파라미터 튜닝에 포함 할지 여부. Default to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>DataFrame</code></dt>
<dd>분류분석 결과</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = False,
    roc: bool = False,
    pr: bool = False,
    multiclass: str = None,
    learning_curve=False,
    report: bool = False,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    algorithm: list = None,
    pruning: bool = False,
    **params,
) -&gt; DataFrame:
    &#34;&#34;&#34;분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 훈련 데이터의 독립변수
        y_train (Series): 훈련 데이터의 종속변수
        x_test (DataFrame, optional): 검증 데이터의 독립변수. Defaults to None.
        y_test (Series, optional): 검증 데이터의 종속변수. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to False.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to False.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to False.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법. Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to False.
        report (bool, optional): 독립변수 보고를 출력할지 여부. Defaults to False.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        algorithm (list, optional): 사용하고자 하는 분류분석 알고리즘 리스트. None으로 설정할 경우 모든 알고리즘 수행 [&#39;logistic&#39;, &#39;knn&#39;, &#39;dtree&#39;, &#39;svc&#39;, &#39;sgd&#39;]. Defaults to None.
        pruning (bool, optional): 의사결정나무에서 가지치기의 alpha값을 하이퍼 파라미터 튜닝에 포함 할지 여부. Default to False.

    Returns:
        DataFrame: 분류분석 결과
    &#34;&#34;&#34;

    results = []  # 결과값을 저장할 리스트
    processes = []  # 병렬처리를 위한 프로세스 리스트
    estimators = {}  # 분류분석 모델을 저장할 딕셔너리
    estimator_names = []  # 분류분석 모델의 이름을 저장할 문자열 리스트

    callstack = []

    if not algorithm or &#34;logistic&#34; in algorithm:
        callstack.append(my_logistic_classification)

    if not algorithm or &#34;knn&#34; in algorithm:
        callstack.append(my_knn_classification)

    if not algorithm or &#34;svc&#34; in algorithm:
        callstack.append(my_svc_classification)

    if not algorithm or &#34;nb&#34; in algorithm:
        callstack.append(my_nb_classification)

    if not algorithm or &#34;dtree&#34; in algorithm:
        callstack.append(my_dtree_classification)

    if not algorithm or &#34;sgd&#34; in algorithm:
        callstack.append(my_sgd_classification)

    # 병렬처리를 위한 프로세스 생성 -&gt; 분류 모델을 생성하는 함수를 각각 호출한다.
    with futures.ThreadPoolExecutor() as executor:
        for c in callstack:
            processes.append(
                executor.submit(
                    c,
                    x_train=x_train,
                    y_train=y_train,
                    x_test=x_test,
                    y_test=y_test,
                    conf_matrix=conf_matrix,
                    cv=cv,
                    hist=hist,
                    roc=roc,
                    pr=pr,
                    multiclass=multiclass,
                    learning_curve=learning_curve,
                    report=report,
                    figsize=figsize,
                    dpi=dpi,
                    sort=sort,
                    is_print=False,
                    **params,
                )
            )

        # 병렬처리 결과를 기다린다.
        for p in futures.as_completed(processes):
            # 각 분류 함수의 결과값(분류모형 객체)을 저장한다.
            estimator = p.result()

            if estimator is not None:
                # 분류모형 객체가 포함하고 있는 성능 평가지표(딕셔너리)를 복사한다.
                scores = estimator.scores
                # 분류모형의 이름과 객체를 저장한다.
                n = estimator.__class__.__name__
                estimator_names.append(n)
                estimators[n] = estimator
                # 성능평가 지표 딕셔너리를 리스트에 저장
                results.append(scores)

        # 결과값을 데이터프레임으로 변환
        result_df = DataFrame(results, index=estimator_names)
        my_pretty_table(result_df)

    return estimators</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_classification_binary_report"><code class="name flex">
<span>def <span class="ident">my_classification_binary_report</span></span>(<span>estimator: <built-in function any>, x: pandas.core.frame.DataFrame = None, y: pandas.core.series.Series = None, sort: str = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>이항로지스틱 회귀분석 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator</code></strong> :&ensp;<code>any</code></dt>
<dd>분류분석 추정기 (모델 객체)</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>독립변수. Defaults to None.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>종속변수. Defaults to None.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification_binary_report(
    estimator: any, x: DataFrame = None, y: Series = None, sort: str = None
) -&gt; None:
    &#34;&#34;&#34;이항로지스틱 회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x (DataFrame, optional): 독립변수. Defaults to None.
        y (Series, optional): 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    if estimator.__class__.__name__ == &#34;LogisticRegression&#34;:
        # 추정 확률
        y_pred_proba = estimator.predict_proba(x)

        # 추정확률의 길이(=샘플수)
        n = len(y_pred_proba)

        # 계수의 수 + 1(절편)
        m = len(estimator.coef_[0]) + 1

        # 절편과 계수를 하나의 배열로 결합
        coefs = np.concatenate([estimator.intercept_, estimator.coef_[0]])

        # 상수항 추가
        x_full = np.matrix(np.insert(np.array(x), 0, 1, axis=1))

        # 변수의 길이를 활용하여 모든 값이 0인 행렬 생성
        ans = np.zeros((m, m))

        # 표준오차
        for i in range(n):
            ans = (
                ans
                + np.dot(np.transpose(x_full[i, :]), x_full[i, :])
                * y_pred_proba[i, 1]
                * y_pred_proba[i, 0]
            )

        vcov = np.linalg.inv(np.matrix(ans))
        se = np.sqrt(np.diag(vcov))

        # t값
        t = coefs / se

        # p-value
        p_values = (1 - norm.cdf(abs(t))) * 2

        # VIF
        if len(x.columns) &gt; 1:
            vif = [
                variance_inflation_factor(x, list(x.columns).index(v))
                for i, v in enumerate(x.columns)
            ]
        else:
            vif = 0

        # 결과표 생성
        xnames = estimator.feature_names_in_

        result_df = DataFrame(
            {
                &#34;종속변수&#34;: [y.name] * len(xnames),
                &#34;독립변수&#34;: xnames,
                &#34;B(비표준화 계수)&#34;: np.round(estimator.coef_[0], 4),
                &#34;표준오차&#34;: np.round(se[1:], 3),
                &#34;t&#34;: np.round(t[1:], 4),
                &#34;유의확률&#34;: np.round(p_values[1:], 3),
                &#34;VIF&#34;: vif,
                &#34;OddsRate&#34;: np.round(np.exp(estimator.coef_[0]), 4),
            }
        )

        if sort:
            if sort.upper() == &#34;V&#34;:
                result_df.sort_values(&#34;VIF&#34;, inplace=True)
            elif sort.upper() == &#34;P&#34;:
                result_df.sort_values(&#34;유의확률&#34;, inplace=True)

        my_pretty_table(result_df)
    else:
        # VIF
        if len(x.columns) &gt; 1:
            vif = [
                variance_inflation_factor(x, list(x.columns).index(v))
                for i, v in enumerate(x.columns)
            ]
        else:
            vif = 0

        # 결과표 생성
        xnames = estimator.feature_names_in_

        result_df = DataFrame(
            {
                &#34;종속변수&#34;: [y.name] * len(xnames),
                &#34;독립변수&#34;: xnames,
                &#34;VIF&#34;: vif,
            }
        )

        if sort:
            if sort.upper() == &#34;V&#34;:
                result_df.sort_values(&#34;VIF&#34;, inplace=True)

        my_pretty_table(result_df)</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_classification_multiclass_report"><code class="name flex">
<span>def <span class="ident">my_classification_multiclass_report</span></span>(<span>estimator: <built-in function any>, x: pandas.core.frame.DataFrame = None, y: pandas.core.series.Series = None, sort: str = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>다중로지스틱 회귀분석 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator</code></strong> :&ensp;<code>any</code></dt>
<dd>분류분석 추정기 (모델 객체)</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>독립변수. Defaults to None.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>종속변수. Defaults to None.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification_multiclass_report(
    estimator: any,
    x: DataFrame = None,
    y: Series = None,
    sort: str = None,
) -&gt; None:
    &#34;&#34;&#34;다중로지스틱 회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x (DataFrame, optional): 독립변수. Defaults to None.
        y (Series, optional): 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    class_list = list(estimator.classes_)
    class_size = len(class_list)

    if estimator.__class__.__name__ == &#34;LogisticRegression&#34;:
        # 추정 확률
        y_pred_proba = estimator.predict_proba(x)

        # 추정확률의 길이(=샘플수)
        n = len(y_pred_proba)

        for i in range(0, class_size):
            # 계수의 수 + 1(절편)
            m = len(estimator.coef_[i]) + 1

            # 절편과 계수를 하나의 배열로 결합
            coefs = np.concatenate([[estimator.intercept_[i]], estimator.coef_[i]])

            # 상수항 추가
            x_full = np.matrix(np.insert(np.array(x), 0, 1, axis=1))

            # 변수의 길이를 활용하여 모든 값이 0인 행렬 생성
            ans = np.zeros((m, m))

            # 표준오차
            for j in range(n):
                ans = (
                    ans
                    + np.dot(np.transpose(x_full[j, :]), x_full[j, :])
                    * y_pred_proba[j, i]
                )

            vcov = np.linalg.inv(np.matrix(ans))
            se = np.sqrt(np.diag(vcov))

            # t값
            t = coefs / se

            # p-value
            p_values = (1 - norm.cdf(abs(t))) * 2

            # VIF
            if len(x.columns) &gt; 1:
                vif = [
                    variance_inflation_factor(x, list(x.columns).index(v))
                    for i, v in enumerate(x.columns)
                ]
            else:
                vif = 0

            # 결과표 생성
            xnames = estimator.feature_names_in_

            result_df = DataFrame(
                {
                    &#34;종속변수&#34;: [y.name] * len(xnames),
                    &#34;CLASS&#34;: [class_list[i]] * len(xnames),
                    &#34;독립변수&#34;: xnames,
                    &#34;B(계수)&#34;: np.round(estimator.coef_[i], 4),
                    &#34;표준오차&#34;: np.round(se[1:], 3),
                    &#34;t&#34;: np.round(t[1:], 4),
                    &#34;유의확률&#34;: np.round(p_values[1:], 3),
                    &#34;VIF&#34;: vif,
                    &#34;OddsRate&#34;: np.round(np.exp(estimator.coef_[i]), 4),
                }
            )

            if sort:
                if sort.upper() == &#34;V&#34;:
                    result_df.sort_values(&#34;VIF&#34;, inplace=True)
                elif sort.upper() == &#34;P&#34;:
                    result_df.sort_values(&#34;유의확률&#34;, inplace=True)

            my_pretty_table(result_df)
    else:
        for i in range(0, class_size):
            # VIF
            if len(x.columns) &gt; 1:
                vif = [
                    variance_inflation_factor(x, list(x.columns).index(v))
                    for i, v in enumerate(x.columns)
                ]
            else:
                vif = 0

            # 결과표 생성
            xnames = estimator.feature_names_in_

            result_df = DataFrame(
                {
                    &#34;종속변수&#34;: [y.name] * len(xnames),
                    &#34;CLASS&#34;: [class_list[i]] * len(xnames),
                    &#34;독립변수&#34;: xnames,
                    &#34;VIF&#34;: vif,
                }
            )

            if sort:
                if sort.upper() == &#34;V&#34;:
                    result_df.sort_values(&#34;VIF&#34;, inplace=True)

            my_pretty_table(result_df)</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_classification_report"><code class="name flex">
<span>def <span class="ident">my_classification_report</span></span>(<span>estimator: <built-in function any>, x_train: pandas.core.frame.DataFrame = None, y_train: pandas.core.series.Series = None, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, sort: str = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>분류분석 결과를 이항분류와 다항분류로 구분하여 출력한다. 훈련데이터와 검증데이터가 함께 전달 될 경우 검증 데이터를 우선한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator</code></strong> :&ensp;<code>any</code></dt>
<dd>분류분석 추정기 (모델 객체)</dd>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>훈련 데이터의 독립변수. Defaults to None.</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>훈련 데이터의 종속변수. Defaults to None.</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>검증 데이터의 독립변수. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>검증 데이터의 종속변수. Defaults to None.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification_report(
    estimator: any,
    x_train: DataFrame = None,
    y_train: Series = None,
    x_test: DataFrame = None,
    y_test: Series = None,
    sort: str = None,
) -&gt; None:
    &#34;&#34;&#34;분류분석 결과를 이항분류와 다항분류로 구분하여 출력한다. 훈련데이터와 검증데이터가 함께 전달 될 경우 검증 데이터를 우선한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame, optional): 훈련 데이터의 독립변수. Defaults to None.
        y_train (Series, optional): 훈련 데이터의 종속변수. Defaults to None.
        x_test (DataFrame, optional): 검증 데이터의 독립변수. Defaults to None.
        y_test (Series, optional): 검증 데이터의 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    is_binary = len(estimator.classes_) == 2

    if is_binary:
        if x_test is not None and y_test is not None:
            my_classification_binary_report(estimator, x=x_test, y=y_test, sort=sort)
        else:
            my_classification_binary_report(estimator, x=x_train, y=y_train, sort=sort)
    else:
        if x_test is not None and y_test is not None:
            my_classification_multiclass_report(
                estimator, x=x_test, y=y_test, sort=sort
            )
        else:
            my_classification_multiclass_report(
                estimator, x=x_train, y=y_train, sort=sort
            )</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_classification_result"><code class="name flex">
<span>def <span class="ident">my_classification_result</span></span>(<span>estimator: <built-in function any>, x_train: pandas.core.frame.DataFrame = None, y_train: pandas.core.series.Series = None, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, hist: bool = True, roc: bool = True, pr: bool = True, multiclass: str = None, learning_curve: bool = True, cv: int = 10, figsize: tuple = (12, 5), dpi: int = 100, is_print: bool = True) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>회귀분석 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator</code></strong> :&ensp;<code>any</code></dt>
<dd>분류분석 추정기 (모델 객체)</dd>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>hist</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>히스토그램을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>roc</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>ROC Curve를 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>pr</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>PR Curve를 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>multiclass</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>다항분류일 경우, 다항분류 방법(ovo, ovr, None). Defaults to None.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to False.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 10.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (12, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>is_print</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>출력 여부. Defaults to True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification_result(
    estimator: any,
    x_train: DataFrame = None,
    y_train: Series = None,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve: bool = True,
    cv: int = 10,
    figsize: tuple = (12, 5),
    dpi: int = 100,
    is_print: bool = True,
) -&gt; None:
    &#34;&#34;&#34;회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법(ovo, ovr, None). Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to False.
        cv (int, optional): 교차검증 횟수. Defaults to 10.
        figsize (tuple, optional): 그래프의 크기. Defaults to (12, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        is_print (bool, optional): 출력 여부. Defaults to True.
    &#34;&#34;&#34;

    # ------------------------------------------------------
    # 성능평가

    scores = []
    score_names = []

    # 이진분류인지 다항분류인지 구분
    labels = list(estimator.classes_)
    is_binary = len(labels) == 2

    if x_train is not None and y_train is not None:
        # 추정치
        y_train_pred = estimator.predict(x_train)

        if hasattr(estimator, &#34;predict_proba&#34;):
            y_train_pred_proba = estimator.predict_proba(x_train)
            y_train_pred_proba_1 = y_train_pred_proba[:, 1]

        # 의사결정계수 --&gt; 다항로지스틱에서는 사용 X
        y_train_pseudo_r2 = 0

        if is_binary and estimator.__class__.__name__ == &#34;LogisticRegression&#34;:
            y_train_log_loss_test = -log_loss(
                y_train, y_train_pred_proba, normalize=False
            )
            y_train_null = np.ones_like(y_train) * y_train.mean()
            y_train_log_loss_null = -log_loss(y_train, y_train_null, normalize=False)
            y_train_pseudo_r2 = 1 - (y_train_log_loss_test / y_train_log_loss_null)

        # 혼동행렬
        y_train_conf_mat = confusion_matrix(y_train, y_train_pred)

        # 성능평가
        # 의사결정계수, 위양성율, 특이성, AUC는 다항로지스틱에서는 사용 불가
        # 나머지 항목들은 코드 변경 예정
        if is_binary:
            ((TN, FP), (FN, TP)) = y_train_conf_mat

            result = {
                &#34;의사결정계수(Pseudo R2)&#34;: y_train_pseudo_r2,
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_train, y_train_pred),
                &#34;정밀도(Precision)&#34;: precision_score(y_train, y_train_pred),
                &#34;재현율(Recall)&#34;: recall_score(y_train, y_train_pred),
                &#34;위양성율(Fallout)&#34;: FP / (TN + FP),
                &#34;특이성(TNR)&#34;: 1 - (FP / (TN + FP)),
                &#34;F1 Score&#34;: f1_score(y_train, y_train_pred),
            }

            if hasattr(estimator, &#34;predict_proba&#34;):
                result[&#34;AUC&#34;] = roc_auc_score(y_train, y_train_pred_proba_1)
        else:
            result = {
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_train, y_train_pred),
                &#34;정밀도(Precision)&#34;: precision_score(
                    y_train, y_train_pred, average=&#34;macro&#34;
                ),
                &#34;재현율(Recall)&#34;: recall_score(y_train, y_train_pred, average=&#34;micro&#34;),
                &#34;F1 Score&#34;: f1_score(y_train, y_train_pred, average=&#34;macro&#34;),
            }

            if hasattr(estimator, &#34;predict_proba&#34;):
                if multiclass == &#34;ovo&#34; or multiclass == None:
                    result[&#34;AUC(ovo)&#34;] = roc_auc_score(
                        y_train, y_train_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovo&#34;
                    )

                if multiclass == &#34;ovr&#34; or multiclass == None:
                    result[&#34;AUC(ovr)&#34;] = roc_auc_score(
                        y_train, y_train_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovr&#34;
                    )

        scores.append(result)
        score_names.append(&#34;훈련데이터&#34;)

    if x_test is not None and y_test is not None:
        # 추정치
        y_test_pred = estimator.predict(x_test)

        if hasattr(estimator, &#34;predict_proba&#34;):
            y_test_pred_proba = estimator.predict_proba(x_test)
            y_test_pred_proba_1 = y_test_pred_proba[:, 1]

        # 의사결정계수
        y_test_pseudo_r2 = 0

        if is_binary and estimator.__class__.__name__ == &#34;LogisticRegression&#34;:
            y_test_log_loss_test = -log_loss(y_test, y_test_pred_proba, normalize=False)
            y_test_null = np.ones_like(y_test) * y_test.mean()
            y_test_log_loss_null = -log_loss(y_test, y_test_null, normalize=False)
            y_test_pseudo_r2 = 1 - (y_test_log_loss_test / y_test_log_loss_null)

        # 혼동행렬
        y_test_conf_mat = confusion_matrix(y_test, y_test_pred)

        if is_binary:
            # TN,FP,FN,TP
            ((TN, FP), (FN, TP)) = y_test_conf_mat

            # 성능평가
            result = {
                &#34;의사결정계수(Pseudo R2)&#34;: y_test_pseudo_r2,
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_test, y_test_pred),
                &#34;정밀도(Precision)&#34;: precision_score(y_test, y_test_pred),
                &#34;재현율(Recall)&#34;: recall_score(y_test, y_test_pred),
                &#34;위양성율(Fallout)&#34;: FP / (TN + FP),
                &#34;특이성(TNR)&#34;: 1 - (FP / (TN + FP)),
                &#34;F1 Score&#34;: f1_score(y_test, y_test_pred),
            }

            if hasattr(estimator, &#34;predict_proba&#34;):
                result[&#34;AUC&#34;] = roc_auc_score(y_test, y_test_pred_proba_1)
        else:
            result = {
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_test, y_test_pred),
                &#34;정밀도(Precision)&#34;: precision_score(
                    y_test, y_test_pred, average=&#34;macro&#34;
                ),
                &#34;재현율(Recall)&#34;: recall_score(y_test, y_test_pred, average=&#34;macro&#34;),
                &#34;F1 Score&#34;: f1_score(y_test, y_test_pred, average=&#34;macro&#34;),
            }

            if hasattr(estimator, &#34;predict_proba&#34;):
                if multiclass == &#34;ovo&#34; or multiclass == None:
                    result[&#34;AUC(ovo)&#34;] = roc_auc_score(
                        y_test, y_test_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovo&#34;
                    )

                if multiclass == &#34;ovr&#34; or multiclass == None:
                    result[&#34;AUC(ovr)&#34;] = roc_auc_score(
                        y_test, y_test_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovr&#34;
                    )

        scores.append(result)
        score_names.append(&#34;검증데이터&#34;)

    # 각 항목의 설명 추가
    if is_binary:
        result = {
            &#34;의사결정계수(Pseudo R2)&#34;: &#34;로지스틱회귀의 성능 측정 지표로, 1에 가까울수록 좋은 모델&#34;,
            &#34;정확도(Accuracy)&#34;: &#34;예측 결과(TN,FP,TP,TN)가 실제 결과(TP,TN)와 일치하는 정도&#34;,
            &#34;정밀도(Precision)&#34;: &#34;양성으로 예측한 결과(TP,FP) 중 실제 양성(TP)인 비율&#34;,
            &#34;재현율(Recall)&#34;: &#34;실제 양성(TP,FN) 중 양성(TP)으로 예측한 비율&#34;,
            &#34;위양성율(Fallout)&#34;: &#34;실제 음성(FP,TN) 중 양성(FP)으로 잘못 예측한 비율&#34;,
            &#34;특이성(TNR)&#34;: &#34;실제 음성(FP,TN) 중 음성(TN)으로 정확히 예측한 비율&#34;,
            &#34;F1 Score&#34;: &#34;정밀도와 재현율의 조화평균&#34;,
        }

        if hasattr(estimator, &#34;predict_proba&#34;):
            result[&#34;AUC&#34;] = &#34;ROC Curve의 면적으로, 1에 가까울수록 좋은 모델&#34;
    else:
        result = {
            &#34;정확도(Accuracy)&#34;: &#34;예측 결과(TN,FP,TP,TN)가 실제 결과(TP,TN)와 일치하는 정도&#34;,
            &#34;정밀도(Precision)&#34;: &#34;양성으로 예측한 결과(TP,FP) 중 실제 양성(TP)인 비율&#34;,
            &#34;재현율(Recall)&#34;: &#34;실제 양성(TP,FN) 중 양성(TP)으로 예측한 비율&#34;,
            &#34;F1 Score&#34;: &#34;정밀도와 재현율의 조화평균&#34;,
        }

        if hasattr(estimator, &#34;predict_proba&#34;):
            if multiclass == &#34;ovo&#34; or multiclass == None:
                result[&#34;AUC(ovo)&#34;] = &#34;One vs One에 대한 AUC로, 1에 가까울수록 좋은 모델&#34;

            if multiclass == &#34;ovr&#34; or multiclass == None:
                result[&#34;AUC(ovr)&#34;] = (
                    &#34;One vs Rest에 대한 AUC로, 1에 가까울수록 좋은 모델&#34;
                )

    scores.append(result)
    score_names.append(&#34;설명&#34;)

    if is_print:
        print(&#34;[분류분석 성능평가]&#34;)
        result_df = DataFrame(scores, index=score_names)

        if estimator.__class__.__name__ != &#34;LogisticRegression&#34;:
            if &#34;의사결정계수(Pseudo R2)&#34; in result_df.columns:
                result_df.drop(columns=[&#34;의사결정계수(Pseudo R2)&#34;], inplace=True)

        my_pretty_table(result_df.T)

    # 결과값을 모델 객체에 포함시킴
    estimator.scores = scores[-2]

    # ------------------------------------------------------
    # 혼동행렬
    if conf_matrix and is_print:
        print(&#34;\n[혼동행렬]&#34;)

        if x_test is not None and y_test is not None:
            my_confusion_matrix(y_test, y_test_pred, figsize=figsize, dpi=dpi)
        else:
            my_confusion_matrix(y_train, y_train_pred, figsize=figsize, dpi=dpi)

    # ------------------------------------------------------
    # curve
    if is_print:
        if hasattr(estimator, &#34;predict_proba&#34;):

            if x_test is None or y_test is None:
                print(&#34;\n[Roc Curve]&#34;)
                my_roc_curve(
                    estimator,
                    x_train,
                    y_train,
                    hist=hist,
                    roc=roc,
                    pr=pr,
                    multiclass=multiclass,
                    dpi=dpi,
                )
            else:
                print(&#34;\n[Roc Curve]&#34;)
                my_roc_curve(
                    estimator,
                    x_test,
                    y_test,
                    hist=hist,
                    roc=roc,
                    pr=pr,
                    multiclass=multiclass,
                    dpi=dpi,
                )

        # 학습곡선
        if learning_curve:
            print(&#34;\n[학습곡선]&#34;)
            yname = y_train.name

            if x_test is not None and y_test is not None:
                y_df = concat([y_train, y_test])
                x_df = concat([x_train, x_test])
            else:
                y_df = y_train.copy()
                x_df = x_train.copy()

            x_df[yname] = y_df
            x_df.sort_index(inplace=True)

            if cv &gt; 0:
                my_learing_curve(
                    estimator, data=x_df, yname=yname, cv=cv, figsize=figsize, dpi=dpi
                )
            else:
                my_learing_curve(
                    estimator, data=x_df, yname=yname, figsize=figsize, dpi=dpi
                )

        if estimator.__class__.__name__ == &#34;DecisionTreeClassifier&#34;:
            my_tree(estimator)</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_dtree_classification"><code class="name flex">
<span>def <span class="ident">my_dtree_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, cv: int = 5, pruning: bool = False, hist: bool = True, roc: bool = True, pr: bool = True, multiclass: str = None, learning_curve=True, report: bool = True, figsize=(10, 5), dpi: int = 100, sort: str = None, is_print: bool = True, **params) ‑> sklearn.tree._classes.DecisionTreeClassifier</span>
</code></dt>
<dd>
<div class="desc"><p>의사결정나무 분류분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>pruning</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>의사결정나무에서 가지치기의 alpha값을 하이퍼 파라미터 튜닝에 포함 할지 여부. Default to False.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to True.</dd>
<dt>report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.</dt>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
<dt><strong><code>is_print</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>출력 여부. Defaults to True.</dd>
<dt><strong><code>**params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>하이퍼파라미터. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>DecisionTreeClassifier</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_dtree_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    pruning: bool = False,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; DecisionTreeClassifier:
    &#34;&#34;&#34;의사결정나무 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        pruning (bool, optional): 의사결정나무에서 가지치기의 alpha값을 하이퍼 파라미터 튜닝에 포함 할지 여부. Default to False.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        DecisionTreeClassifier
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;criterion&#34;: [&#34;gini&#34;, &#34;entropy&#34;],
                # &#34;min_samples_split&#34;: [2, 3, 4],
                # &#34;min_samples_leaf&#34;: [1, 2, 3],
            }

    return __my_classification(
        classname=DecisionTreeClassifier,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        pruning=pruning,
        **params,
    )</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_knn_classification"><code class="name flex">
<span>def <span class="ident">my_knn_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, cv: int = 5, hist: bool = True, roc: bool = True, pr: bool = True, multiclass: str = None, learning_curve=True, report: bool = True, figsize=(10, 5), dpi: int = 100, sort: str = None, is_print: bool = True, **params) ‑> sklearn.neighbors._classification.KNeighborsClassifier</span>
</code></dt>
<dd>
<div class="desc"><p>KNN 분류분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>hist</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>히스토그램을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>roc</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>ROC Curve를 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>pr</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>PR Curve를 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>multiclass</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>다항분류일 경우, 다항분류 방법. Defaults to None.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to True.</dd>
<dt>report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.</dt>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
<dt><strong><code>is_print</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>출력 여부. Defaults to True.</dd>
<dt><strong><code>**params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>하이퍼파라미터. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>KNeighborsClassifier</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_knn_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; KNeighborsClassifier:
    &#34;&#34;&#34;KNN 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법. Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        KNeighborsClassifier
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;n_neighbors&#34;: [3, 5, 7],
                &#34;weights&#34;: [&#34;uniform&#34;, &#34;distance&#34;],
                &#34;metric&#34;: [&#34;euclidean&#34;, &#34;manhattan&#34;],
            }

    return __my_classification(
        classname=KNeighborsClassifier,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        **params,
    )</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_linear_svc_classification"><code class="name flex">
<span>def <span class="ident">my_linear_svc_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, cv: int = 5, learning_curve=True, report: bool = True, figsize=(10, 5), dpi: int = 100, is_print: bool = True, **params) ‑> sklearn.svm._classes.LinearSVC</span>
</code></dt>
<dd>
<div class="desc"><p>선형 SVM 분류분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>is_print</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>출력 여부. Defaults to True.</dd>
<dt><strong><code>**params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>하이퍼파라미터. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>LinearSVC</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_linear_svc_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    is_print: bool = True,
    **params,
) -&gt; LinearSVC:
    &#34;&#34;&#34;선형 SVM 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        LinearSVC
    &#34;&#34;&#34;

    if &#34;hist&#34; in params:
        del params[&#34;hist&#34;]
    if &#34;roc&#34; in params:
        del params[&#34;roc&#34;]
    if &#34;pr&#34; in params:
        del params[&#34;pr&#34;]
    if &#34;report&#34; in params:
        del params[&#34;report&#34;]

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;penalty&#34;: [&#34;l1&#34;, &#34;l2&#34;],
                &#34;loss&#34;: [&#34;squared_hinge&#34;, &#34;hinge&#34;],
                &#34;C&#34;: [0.01, 0.1, 1, 10],
                &#34;max_iter&#34;: [1000],
                &#34;dual&#34;: [True, False],
            }

    return __my_classification(
        classname=LinearSVC,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        is_print=is_print,
        **params,
    )</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_logistic_classification"><code class="name flex">
<span>def <span class="ident">my_logistic_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, cv: int = 5, hist: bool = True, roc: bool = True, pr: bool = True, multiclass: str = None, learning_curve=True, report: bool = True, figsize=(10, 5), dpi: int = 100, sort: str = None, is_print: bool = True, **params) ‑> sklearn.linear_model._logistic.LogisticRegression</span>
</code></dt>
<dd>
<div class="desc"><p>로지스틱 회귀분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>hist</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>히스토그램을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>roc</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>ROC Curve를 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>pr</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>PR Curve를 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>multiclass</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>다항분류일 경우, 다항분류 방법. Defaults to None.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to True.</dd>
<dt>report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.</dt>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
<dt><strong><code>is_print</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>출력 여부. Defaults to True.</dd>
<dt><strong><code>**params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>하이퍼파라미터. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>LogisticRegression</code></dt>
<dd>회귀분석 모델</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_logistic_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; LogisticRegression:
    &#34;&#34;&#34;로지스틱 회귀분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법. Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        LogisticRegression: 회귀분석 모델
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;penalty&#34;: [&#34;l1&#34;, &#34;l2&#34;, &#34;elasticnet&#34;],
                &#34;C&#34;: [0.001, 0.01, 0.1, 1, 10, 100],
                &#34;max_iter&#34;: [1000],
            }

    return __my_classification(
        classname=LogisticRegression,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        **params,
    )</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_nb_classification"><code class="name flex">
<span>def <span class="ident">my_nb_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, cv: int = 5, hist: bool = True, roc: bool = True, pr: bool = True, multiclass: str = None, learning_curve=True, report: bool = True, figsize=(10, 5), dpi: int = 100, sort: str = None, is_print: bool = True, **params) ‑> sklearn.naive_bayes.GaussianNB</span>
</code></dt>
<dd>
<div class="desc"><p>나이브베이즈 분류분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to True.</dd>
<dt>report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.</dt>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
<dt><strong><code>is_print</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>출력 여부. Defaults to True.</dd>
<dt><strong><code>**params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>하이퍼파라미터. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>SVC</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_nb_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; GaussianNB:
    &#34;&#34;&#34;나이브베이즈 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        SVC
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                # &#34;priors&#34; : None,
                &#34;var_smoothing&#34;: [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]
            }

    return __my_classification(
        classname=GaussianNB,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        **params,
    )</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_sgd_classification"><code class="name flex">
<span>def <span class="ident">my_sgd_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, cv: int = 5, hist: bool = True, roc: bool = True, pr: bool = True, multiclass: str = None, learning_curve=True, report: bool = True, figsize=(10, 5), dpi: int = 100, sort: str = None, is_print: bool = True, **params) ‑> sklearn.linear_model._stochastic_gradient.SGDClassifier</span>
</code></dt>
<dd>
<div class="desc"><p>SGD 분류분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to True.</dd>
<dt>report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.</dt>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
<dt><strong><code>is_print</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>출력 여부. Defaults to True.</dd>
<dt><strong><code>**params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>하이퍼파라미터. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>SGDClassifier</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_sgd_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    is_print: bool = True,
    **params,
) -&gt; SGDClassifier:
    &#34;&#34;&#34;SGD 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        SGDClassifier
    &#34;&#34;&#34;

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                # 손실함수
                # &#39;log_loss&#39;, &#39;squared_hinge&#39;, &#39;perceptron&#39;, &#39;squared_error&#39;, &#39;hinge&#39;, &#39;huber&#39;, &#39;squared_epsilon_insensitive&#39;, &#39;epsilon_insensitive&#39;, &#39;modified_huber&#39;
                &#34;loss&#34;: [&#34;hinge&#34;, &#34;log_loss&#34;, &#34;modified_huber&#34;],
                # 정규화 종류
                &#34;penalty&#34;: [&#34;l2&#34;, &#34;l1&#34;, &#34;elasticnet&#34;],
                # 정규화 강도(값이 낮을 수록 약한 정규화)
                &#34;alpha&#34;: [0.0001, 0.001, 0.01, 0.1],
                # 최대 반복 수행 횟수
                &#34;max_iter&#34;: [1000, 2000, 3000, 4000, 5000],
                # 학습률 스케줄링 전략
                &#34;learning_rate&#34;: [&#34;optimal&#34;, &#34;constant&#34;, &#34;invscaling&#34;, &#34;adaptive&#34;],
                # 초기 학습률
                &#34;eta0&#34;: [0.01, 0.1, 0.5],
            }

    return __my_classification(
        classname=SGDClassifier,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        hist=hist,
        roc=roc,
        pr=pr,
        multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        sort=sort,
        is_print=is_print,
        **params,
    )</code></pre>
</details>
</dd>
<dt id="hossam.classification.my_svc_classification"><code class="name flex">
<span>def <span class="ident">my_svc_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, cv: int = 5, learning_curve=True, report: bool = True, figsize=(10, 5), dpi: int = 100, is_print: bool = True, **params) ‑> sklearn.svm._classes.SVC</span>
</code></dt>
<dd>
<div class="desc"><p>SVC 분류분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to True.</dd>
<dt>report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.</dt>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>is_print</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>출력 여부. Defaults to True.</dd>
<dt><strong><code>**params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>하이퍼파라미터. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>SVC</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_svc_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    cv: int = 5,
    # hist: bool = True,
    # roc: bool = True,
    # pr: bool = True,
    # multiclass: str = None,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    is_print: bool = True,
    **params,
) -&gt; SVC:
    &#34;&#34;&#34;SVC 분류분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        is_print (bool, optional): 출력 여부. Defaults to True.
        **params (dict, optional): 하이퍼파라미터. Defaults to None.
    Returns:
        SVC
    &#34;&#34;&#34;

    if &#34;hist&#34; in params:
        del params[&#34;hist&#34;]
    if &#34;roc&#34; in params:
        del params[&#34;roc&#34;]
    if &#34;pr&#34; in params:
        del params[&#34;pr&#34;]
    if &#34;report&#34; in params:
        del params[&#34;report&#34;]

    # 교차검증 설정
    if cv &gt; 0:
        if not params:
            params = {
                &#34;C&#34;: [0.1, 1, 10],
                # &#34;kernel&#34;: [&#34;rbf&#34;, &#34;linear&#34;, &#34;poly&#34;, &#34;sigmoid&#34;],
                &#34;kernel&#34;: [&#34;rbf&#34;, &#34;poly&#34;, &#34;sigmoid&#34;],
                &#34;degree&#34;: [2, 3, 4, 5],
                # &#34;gamma&#34;: [&#34;scale&#34;, &#34;auto&#34;],
                # &#34;coef0&#34;: [0.01, 0.1, 1, 10],
                # &#34;shrinking&#34;: [True, False],
                # &#34;probability&#34;: [True],  # AUC 값 확인을 위해서는 True로 설정
            }

    return __my_classification(
        classname=SVC,
        x_train=x_train,
        y_train=y_train,
        x_test=x_test,
        y_test=y_test,
        conf_matrix=conf_matrix,
        cv=cv,
        # hist=hist,
        # roc=roc,
        # pr=pr,
        # multiclass=multiclass,
        learning_curve=learning_curve,
        report=report,
        figsize=figsize,
        dpi=dpi,
        is_print=is_print,
        **params,
    )</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="hossam" href="index.html">hossam</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="hossam.classification.my_classification" href="#hossam.classification.my_classification">my_classification</a></code></li>
<li><code><a title="hossam.classification.my_classification_binary_report" href="#hossam.classification.my_classification_binary_report">my_classification_binary_report</a></code></li>
<li><code><a title="hossam.classification.my_classification_multiclass_report" href="#hossam.classification.my_classification_multiclass_report">my_classification_multiclass_report</a></code></li>
<li><code><a title="hossam.classification.my_classification_report" href="#hossam.classification.my_classification_report">my_classification_report</a></code></li>
<li><code><a title="hossam.classification.my_classification_result" href="#hossam.classification.my_classification_result">my_classification_result</a></code></li>
<li><code><a title="hossam.classification.my_dtree_classification" href="#hossam.classification.my_dtree_classification">my_dtree_classification</a></code></li>
<li><code><a title="hossam.classification.my_knn_classification" href="#hossam.classification.my_knn_classification">my_knn_classification</a></code></li>
<li><code><a title="hossam.classification.my_linear_svc_classification" href="#hossam.classification.my_linear_svc_classification">my_linear_svc_classification</a></code></li>
<li><code><a title="hossam.classification.my_logistic_classification" href="#hossam.classification.my_logistic_classification">my_logistic_classification</a></code></li>
<li><code><a title="hossam.classification.my_nb_classification" href="#hossam.classification.my_nb_classification">my_nb_classification</a></code></li>
<li><code><a title="hossam.classification.my_sgd_classification" href="#hossam.classification.my_sgd_classification">my_sgd_classification</a></code></li>
<li><code><a title="hossam.classification.my_svc_classification" href="#hossam.classification.my_svc_classification">my_svc_classification</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>